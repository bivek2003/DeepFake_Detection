Metadata-Version: 2.4
Name: deepfake-detector
Version: 0.1.0
Summary: A comprehensive deepfake detection system for images, videos, and audio
Home-page: https://github.com/bivek2003/DeepFake_Detection
Author: Bivek Sharma Panthi
Author-email: sharmabivek12@gmail.com
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Multimedia :: Video
Classifier: Topic :: Multimedia :: Sound/Audio
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENCE
Requires-Dist: torch>=1.12.0
Requires-Dist: torchvision>=0.13.0
Requires-Dist: torchaudio>=0.12.0
Requires-Dist: opencv-python>=4.6.0
Requires-Dist: scikit-learn>=1.1.0
Requires-Dist: numpy>=1.21.0
Requires-Dist: pandas>=1.4.0
Requires-Dist: librosa>=0.9.2
Requires-Dist: soundfile>=0.10.3
Requires-Dist: Pillow>=9.0.0
Requires-Dist: matplotlib>=3.5.0
Requires-Dist: seaborn>=0.11.0
Requires-Dist: tqdm>=4.64.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: requests>=2.28.0
Requires-Dist: pytest>=7.0.0
Requires-Dist: jupyter>=1.0.0
Requires-Dist: black>=22.0.0
Requires-Dist: flake8>=5.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: flake8>=5.0.0; extra == "dev"
Requires-Dist: jupyter>=1.0.0; extra == "dev"
Provides-Extra: gpu
Requires-Dist: torch[cu117]>=1.12.0; extra == "gpu"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# 🎭 Deepfake Detection System

A comprehensive, production-ready deepfake detection system supporting images, videos, and audio. Built with PyTorch and following industry best practices for scalable machine learning applications.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## 🎯 Features

### Phase 1: Data Pipeline (✅ Complete)
- **Multi-Dataset Support**: FaceForensics++, DFDC, Celeb-DF, WildDeepfake, ASVspoof 2021, FakeAVCeleb
- **Video Processing**: Face detection, extraction, and alignment with OpenCV
- **Audio Processing**: MFCC, spectral features, voice activity detection with librosa
- **PyTorch Integration**: Efficient datasets and dataloaders with augmentation
- **Data Management**: Automated splitting, validation, and metadata tracking

### Upcoming Phases
- **Phase 2**: Model Development (EfficientNet, Vision Transformers, AASIST)
- **Phase 3**: Backend API (FastAPI, real-time processing)
- **Phase 4**: Frontend Interface (React, mobile support)
- **Phase 5**: Deployment (Docker, Kubernetes, cloud)
- **Phase 6**: Optimization (TensorRT, quantization)
- **Phase 7**: Ethics & Explainability (Grad-CAM, bias mitigation)

## 🚀 Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/bivek2003/DeepFake_Detection.git
cd DeepFake-Detection

# Install dependencies
pip install -r requirements.txt

# Setup development environment
make setup
```
## 📁 Project Structure

```
DeepFake-Detection/
├── src/deepfake_detector/          # Main package
│   ├── data/                       # Data processing modules
│   │   ├── dataset_manager.py      # Dataset registry and management
│   │   ├── video_processor.py      # Video processing pipeline
│   │   ├── audio_processor.py      # Audio feature extraction
│   │   ├── data_pipeline.py        # PyTorch integration
│   │   └── __init__.py
│   ├── models/                     # Model architectures (Phase 2)
│   ├── utils/                      # Utilities and configuration
│   └── __init__.py
├── datasets/                       # Raw datasets
├── preprocessed/                   # Processed data
├── logs/                          # Application logs
├── tests/                         # Unit tests
├── requirements.txt               # Dependencies
├── setup.py                      # Package setup
├── Makefile                      # Development commands
└── README.md                     # Documentation
```

## 🎬 Supported Datasets

| Dataset | Type | Size | Description |
|---------|------|------|-------------|
| **FaceForensics++** | Video | 38.5 GB | 1,000 videos, 1.8M manipulated images |
| **DFDC** | Video | 470 GB | 100K+ clips from 3,426 actors |
| **Celeb-DF** | Video | 15.8 GB | 590 originals + 5,639 deepfakes |
| **WildDeepfake** | Video | 4.2 GB | 707 "in-the-wild" deepfake videos |
| **DeeperForensics-1.0** | Video | 2,000 GB | 60K videos with rich perturbations |
| **ASVspoof 2021** | Audio | 23.1 GB | TTS/VC speech deepfake dataset |
| **FakeAVCeleb** | Multimodal | 87.5 GB | Synchronized video + audio deepfakes |

**Total Dataset Size**: ~2.6 TB

## 🔧 Configuration

The system uses YAML configuration files for easy customization:

```yaml
# config.yaml
data:
  data_root: "./datasets"
  video_target_size: [224, 224]
  audio_sample_rate: 16000
  test_size: 0.2
  val_size: 0.1

training:
  batch_size: 32
  learning_rate: 1e-4
  num_epochs: 50
  device: "auto"

logging:
  level: "INFO"
  file_logging: true
  log_dir: "./logs"
```

## 📊 Data Processing Pipeline

### Video Processing
1. **Face Detection**: OpenCV Haar cascades or DNN models
2. **Face Extraction**: Automatic cropping with padding
3. **Alignment & Resizing**: Standardized 224×224 RGB images
4. **Quality Analysis**: Resolution, FPS, face detection rate scoring
5. **Augmentation**: Flips, rotations, color jitter, compression artifacts

### Audio Processing  
1. **Loading**: Multi-format support (WAV, MP3, FLAC)
2. **Resampling**: Standardized 16kHz mono audio
3. **Feature Extraction**: MFCC, spectral features, mel spectrograms
4. **Voice Activity Detection**: Automatic silence removal
5. **Augmentation**: Noise addition, pitch shifting, time stretching

### Data Pipeline
1. **Stratified Splitting**: Maintains class balance across train/val/test
2. **PyTorch Integration**: Efficient datasets and dataloaders
3. **Batch Processing**: Parallel processing with configurable workers
4. **Memory Management**: Optional preloading for faster training
5. **Metadata Tracking**: Comprehensive logging and validation

## 💻 Development

### Make Commands

```bash
make install          # Install dependencies
make install-dev      # Install with development tools
make test            # Run tests
make lint            # Check code style
make format          # Format code with black
make clean           # Clean generated files
make setup           # Full project setup
```

### Adding New Datasets

```python
from deepfake_detector.data import DatasetRegistry, DatasetInfo

# Register new dataset
registry = DatasetRegistry()
registry.datasets["new_dataset"] = DatasetInfo(
    name="New Deepfake Dataset",
    type="video",
    url="https://example.com/dataset",
    description="Custom deepfake dataset",
    file_count=1000,
    size_gb=50.0
)
```

## 🧪 Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test category
pytest tests/test_video_processor.py -v
pytest tests/test_audio_processor.py -v

# Run with coverage
pytest tests/ --cov=src/deepfake_detector --cov-report=html
```

## 📈 Performance

### Video Processing Benchmarks
- **Face Detection**: ~30 FPS on CPU, ~100 FPS on GPU
- **Feature Extraction**: 224×224 faces at 60 FPS
- **Batch Processing**: 4× speedup with parallel workers

### Audio Processing Benchmarks  
- **Feature Extraction**: Real-time processing (3s audio in <0.1s)
- **MFCC Computation**: 13 coefficients in ~10ms
- **Batch Processing**: 8× speedup with multiprocessing

### Memory Usage
- **Video Dataset**: ~2GB RAM for 10K samples (with preloading)
- **Audio Dataset**: ~1GB RAM for 50K samples (MFCC features)
- **Streaming Mode**: <100MB RAM (no preloading)

## 🔬 Technical Details

### Video Architecture
- **Face Detection**: OpenCV Haar cascades (fast) or DNN models (accurate)
- **Preprocessing**: Face alignment, padding, normalization
- **Augmentation**: TorchVision transforms with custom video-specific augmentations
- **Quality Scoring**: Multi-factor analysis (resolution, FPS, face detection rate)

### Audio Architecture
- **Feature Extraction**: Librosa-based pipeline with 13 MFCC coefficients
- **Voice Activity Detection**: Energy and zero-crossing rate thresholding
- **Augmentation**: Time-domain and frequency-domain transformations
- **Quality Analysis**: SNR estimation, spectral quality metrics

### Data Pipeline Architecture
- **Stratified Splitting**: Maintains class distribution across splits
- **PyTorch Integration**: Custom Dataset classes with efficient loading
- **Parallel Processing**: ThreadPoolExecutor for I/O bound operations
- **Error Handling**: Graceful degradation with fallback mechanisms

## 🔮 Roadmap

### Phase 2: Model Development (Next)
- [ ] EfficientNet backbone for video classification
- [ ] Vision Transformer integration
- [ ] AASIST audio architecture
- [ ] Ensemble methods and model fusion
- [ ] Cross-dataset evaluation

### Phase 3: API Development
- [ ] FastAPI backend with async processing
- [ ] WebSocket support for real-time streams
- [ ] Rate limiting and authentication
- [ ] Comprehensive API documentation

### Phase 4: Frontend Development
- [ ] React web interface
- [ ] React Native mobile app
- [ ] Real-time camera processing
- [ ] Progressive Web App (PWA)

### Phase 5: Production Deployment
- [ ] Docker containerization
- [ ] Kubernetes orchestration  
- [ ] CI/CD pipelines
- [ ] Cloud deployment (AWS/GCP/Azure)

### Phase 6: Optimization
- [ ] TensorRT acceleration
- [ ] Model quantization
- [ ] On-device inference
- [ ] Real-time performance (30+ FPS)

### Phase 7: Ethics & Explainability
- [ ] Grad-CAM visualizations
- [ ] Bias detection and mitigation
- [ ] Fairness metrics
- [ ] Responsible AI guidelines

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes following the code style
4. Run tests (`make test`)
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Code Style
- Follow PEP 8 guidelines
- Use Black for code formatting
- Add type hints where possible
- Write comprehensive docstrings
- Maintain test coverage >90%

## 📞 Support

- 📧 Email: sharmabivek12@gmail.com
- 🐛 Issues: [GitHub Issues](https://github.com/bivek2003/DeepFake_Detection/issues)
- 📖 Documentation: [Project Wiki](https://github.com/bivek2003/DeepFake_Detection/wiki)

## 🙏 Acknowledgments

- **FaceForensics++** team for the foundational dataset
- **DFDC Challenge** organizers for the comprehensive benchmark
- **ASVspoof** community for audio spoofing research
- **PyTorch** team for the excellent deep learning framework
- **OpenCV** and **librosa** communities for robust media processing tools

## 📊 Citation

If you use this project in your research, please cite:

```bibtex
@misc{deepfake-detector-2025,
  title={Comprehensive Deepfake Detection System},
  author={Bivek Sharma Panthi},
  year={2025},
  url={https://github.com/bivek2003/DeepFake_Detection}
}
```

---

**⭐ Star this repository if you find it helpful!**
